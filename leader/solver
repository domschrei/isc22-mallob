#!/usr/bin/env python3
import json
import logging
import os
import subprocess
import sys
import threading
import time
from threading import Timer

import signal
from subprocess import Popen
from subprocess import TimeoutExpired
from typing import Callable

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# Class to help identify when a timeout has been triggered
class _TimeoutRecorder:
    __timed_out: bool = False

    def record_timeout(self):
        self.__timed_out = True

    def is_timed_out(self) -> bool:
        return self.__timed_out

class Runner:
    def __init__(self, request_directory: str):
        self.logger = logging.getLogger("Runner")
        self.logger.setLevel(logging.INFO)
        self.request_directory = request_directory
        os.environ['PYTHONUNBUFFERED'] = "1"
        self.sigterm_grace_seconds = 10

    def killpg_if_running(self, process: Popen, sigkill_grace_seconds: int, post_kill_hook: Callable[[], None] = None) -> None:
        self.__sendpg_signal(process, signal.SIGTERM, post_kill_hook)
        try:
            process.wait(sigkill_grace_seconds)
        except TimeoutExpired:
            self.__sendpg_signal(process, signal.SIGKILL)


    def __sendpg_signal(self, proc: Popen, proc_signal: signal.Signals, post_kill_hook: Callable[[], None] = None) -> None:
        try:
            pg_id = os.getpgid(proc.pid)
            self.logger.info("Sending %s to process group %d for process %d", proc_signal, pg_id, proc.pid)
            os.killpg(pg_id, proc_signal)
            if post_kill_hook:
                post_kill_hook()
        except ProcessLookupError:
            # Process not found, so we can assume it has already ended. This can happen because of
            # race-conditions around when the process finishes, this method is called, and timeout
            # cancelled
            self.logger.debug("No process group for process %d found. Ignoring %s.", proc.pid, proc_signal)

    def process_stream(self, stream, str_name, file_handle):
        line = stream.readline()
        while line != "":
            self.logger.info(f"{str_name}: {line}")
            file_handle.write(line)
            line = stream.readline()

    def run(self, cmd: list, timeout_seconds, is_append):
        self.logger.info("Running command: %s", str(cmd))
        
        stdout_target_loc = os.path.join(self.request_directory, "stdout.log")
        stderr_target_loc = os.path.join(self.request_directory, "stderr.log")
        
        access = "a" if is_append else "w"

        with open(stdout_target_loc, access) as stdout_handle:
            with open(stderr_target_loc, access) as stderr_handle:
                start = time.monotonic()
                proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                    universal_newlines=True, start_new_session=True)
                stdout_t = threading.Thread(target = self.process_stream, args=(proc.stdout, "STDOUT", stdout_handle))
                stderr_t = threading.Thread(target = self.process_stream, args=(proc.stderr, "STDERR", stderr_handle))
                stdout_t.start()
                stderr_t.start()
                timeout_recorder = _TimeoutRecorder()
                timeout_timer = Timer(
                    timeout_seconds + self.sigterm_grace_seconds,
                    lambda: self.killpg_if_running(process=proc,
                                                        # Arbitrarily picked to fail fast
                                                        sigkill_grace_seconds=3,
                                                        post_kill_hook=timeout_recorder.record_timeout))
                try: 
                    timeout_timer.start()
                    return_code = proc.wait()
                except Exception as e:
                    self.logger.info(f"Exception occurred during job run: {e}")
                    if not return_code:
                        return_code = -1
                finally:
                    timeout_timer.cancel()
                    stdout_t.join()
                    stderr_t.join()

                stop = time.monotonic()
                timing = stop-start
                timing_str = f">>>>>{cmd[0]} : {timing} seconds<<<<<\n"
                self.logger.info(f"STDERR: {timing_str}")
                stderr_handle.write(timing_str)
                
        return {
            "stdout": stdout_target_loc,
            "stderr": stderr_target_loc,
            "return_code": return_code,
            "time": timing,
            "timed_out": timeout_recorder.is_timed_out(),
            "output_directory": self.request_directory
        }

    def get_input_json(self):
        input = os.path.join(self.request_directory, "input.json")
        with open(input) as f:
            return json.loads(f.read())
    
    def create_hostfile(self,ips, request_dir):
        hostfile_path = os.path.join(request_dir, 'combined_hostfile')
        with open(hostfile_path, 'w+') as f:
            for ip in ips:
                #f.write(f'{ip} slots=4') # Cloud track
                f.write(f'{ip} slots=16') # Parallel track
                f.write('\n')
            return hostfile_path

    def get_command(self, input_json):
        problem_path = input_json.get("problem_path")
        worker_node_ips = input_json.get("worker_node_ips", [])
        
        combined_hostfile = self.create_hostfile(worker_node_ips, self.request_directory)

        run_list = ["/competition/run_mallob.sh"]
        run_list.append(combined_hostfile)
        run_list.append(problem_path)

        return run_list


class MallobParser:
    @staticmethod
    def get_result(output_file):
        """
        TODO: Participants should replace this with something more robust for their own solver!
        """
        with open(output_file) as f:
            raw_logs = f.read()
            if "s UNSATISFIABLE" in raw_logs:
                return "UNSATISFIABLE"
            elif "s SATISFIABLE" in raw_logs:
                return "SATISFIABLE"
            elif "result SAT" in raw_logs:
                return "SATISFIABLE"
            elif "result UNSAT" in raw_logs:
                return "UNSATISFIABLE"
            elif "[ERROR]" in raw_logs:
                return "ERROR"
            else:
                return "UNKNOWN"

if __name__ == "__main__":
    
    request_directory = sys.argv[1]
    runner = Runner(request_directory)
    runner.logger.info(f"Hello from /competition/solver.  Request directory is {request_directory}")
    
    input_json = runner.get_input_json()
    cmd = runner.get_command(input_json)
    
    runner.logger.info("Running solver ...")
    
    output = runner.run(cmd, 1000, False)
    result = MallobParser.get_result(output["stdout"])
    logging.info(f"RESULT: {result}")
    solver_output = {
        "return_code": output["return_code"],
        "result": result,
        "artifacts": {
            "stdout_path": output["stdout"],
            "stderr_path": output["stderr"]
        }
    }
    
    with open(os.path.join(request_directory, "solver_out.json"), "w+") as f:
        f.write(json.dumps(solver_output))
